{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64843913",
   "metadata": {},
   "source": [
    "# Feature Extraction Phase\n",
    "In this notebook I'm running the feature extraction phase using an Inception Convolutional Neural Network as the feature extraction model trained with the pre-processed data as well as optimized with a Bayesian Optimization process.\n",
    "\n",
    "**Author**: Arthur G."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268fbc8a",
   "metadata": {},
   "source": [
    "## Loading Dependencies\n",
    "Loading and setting up all the dependencies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe82203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 16:10:23.553184: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-23 16:10:23.770923: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-23 16:10:23.830532: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-23 16:10:23.830545: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-23 16:10:23.866913: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-23 16:10:24.588467: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-23 16:10:24.588543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-23 16:10:24.588548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# libs\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pycaret.classification import *\n",
    "from keras_tuner import HyperModel, Objective\n",
    "from keras_tuner.tuners import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# settings\n",
    "seed = np.random.seed(42)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df050263",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "A set of helper functions and classes for the automation of model optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd044fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionHyperModel(HyperModel):\n",
    "    \"\"\"Builds the base Inception model for dynamic optimization.\"\"\"\n",
    "    \n",
    "    def build(self, hp):\n",
    "        \"\"\"Initiate the model before the bayesian process gets started.\"\"\"\n",
    "        input_tensor = tf.keras.layers.Input(shape=(1, 300, 20)) # era 1,300,1\n",
    "\n",
    "        \n",
    "        # bottleneck layer\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "                filters=hp.Int(\"n_filters_1_bn\", min_value=16, max_value=64, step=16), \n",
    "                kernel_size=(1, 1), \n",
    "                strides=1, \n",
    "                padding='same', \n",
    "                activation='relu'\n",
    "        )(input_tensor)\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "                filters=hp.Int(\"n_filters_2_bn\", min_value=16, max_value=64, step=16), \n",
    "                kernel_size=hp.Int(\"kernel_size_bn\", min_value=2, max_value=4, step=1), \n",
    "                strides=1, \n",
    "                padding='same', \n",
    "                activation='relu'\n",
    "        )(x)\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "                filters=hp.Int(\"n_filters_3_bn\", min_value=16, max_value=64, step=16), \n",
    "                kernel_size=(1, 1), \n",
    "                strides=1, \n",
    "                padding='same', \n",
    "                activation='relu'\n",
    "        )(x)\n",
    "        x = tf.keras.layers.Dropout(\n",
    "                hp.Choice(\"dropout_rate_bn\", values=[0.05, 0.5], default=0.5)\n",
    "        )(x)\n",
    "        \n",
    "\n",
    "        # dynamic efficient inception blocks\n",
    "        for i in range(hp.Int(\"n_incep_blocks\", min_value=2, max_value=4, step=1)):\n",
    "            x = tf.keras.layers.Conv2D(\n",
    "                    filters=hp.Int(\"n_filters_1_ib\", min_value=16, max_value=64, step=16), \n",
    "                    kernel_size=(1, 1), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\"\n",
    "            )(x)\n",
    "            x = tf.keras.layers.Conv2D(\n",
    "                    filters=hp.Int(\"n_filters_2_ib\", min_value=16, max_value=64, step=16), \n",
    "                    kernel_size=(1, 1), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\"\n",
    "            )(x)\n",
    "            x = tf.keras.layers.Conv2D(\n",
    "                    filters=hp.Int(\"n_filters_3_ib\", min_value=16, max_value=64, step=16), \n",
    "                    kernel_size=(3, 3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\"\n",
    "            )(x)\n",
    "            x = tf.keras.layers.Conv2D(\n",
    "                    filters=hp.Int(\"n_filters_4_ib\", min_value=16, max_value=64, step=16), \n",
    "                    kernel_size=(1, 1), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\"\n",
    "            )(x)\n",
    "            x = tf.keras.layers.Conv2D(\n",
    "                    filters=hp.Int(\"n_filters_5_ib\", min_value=16, max_value=64, step=16), \n",
    "                    kernel_size=(5, 5), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\"\n",
    "            )(x)\n",
    "            x = tf.keras.layers.MaxPooling2D(\n",
    "                    pool_size=(3, 3), \n",
    "                    strides=(1, 1), \n",
    "                    padding='same'\n",
    "            )(x)\n",
    "            x = tf.keras.layers.Conv2D(\n",
    "                filters=hp.Int(\"n_filters_6_ib\", min_value=16, max_value=64, step=16), \n",
    "                kernel_size=(1, 1), \n",
    "                padding=\"same\", \n",
    "                activation=\"relu\"\n",
    "            )(x)\n",
    "        \n",
    "\n",
    "        # fully connected layer\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        \n",
    "        for i in range(hp.Int(\"n_fc_blocks\", min_value=2, max_value=4, step=1)):\n",
    "            x = tf.keras.layers.Dense(\n",
    "                    units=hp.Int(\"n_dense_nodes_1_fc\", min_value=32, max_value=256, step=32), \n",
    "                    activation='relu'\n",
    "            )(x)\n",
    "            x = tf.keras.layers.Dropout(\n",
    "                    hp.Choice(\"dropout_rate_fc\", values=[0.05, 0.5], default=0.5)\n",
    "            )(x)\n",
    "            x = tf.keras.layers.Dense(\n",
    "                    units=hp.Int(\n",
    "                        \"n_dense_nodes_2_fc\", min_value=32, max_value=256, step=32) \\\n",
    "                        // hp.Int(\"dense_nodes_div\", min_value=2, max_value=8, step=2), \n",
    "                        activation='relu'\n",
    "            )(x)\n",
    "        \n",
    "        output_tensor = tf.keras.layers.Dense(\n",
    "            4, \n",
    "            activation='softmax'\n",
    "        )(x)\n",
    "        \n",
    "\n",
    "        # model compilation\n",
    "        model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "        model.compile(\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'],\n",
    "            optimizer=hp.Choice(\n",
    "                \"optimizer\", \n",
    "                values=[\n",
    "                    \"sgd\", \"rmsprop\", \"adam\", \n",
    "                    \"adadelta\", \"adagrad\", \n",
    "                    \"adamax\", \"nadam\"\n",
    "                ], default=\"adam\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "\n",
    "def get_features_extracted(model, final_layer: str, sample: np.ndarray):\n",
    "    \"\"\"\n",
    "    This function extracts outputs from a given layer\n",
    "    name.\n",
    "    \"\"\"\n",
    "    sample = np.expand_dims(sample, axis=0)\n",
    "    output = np.array(\n",
    "        tf.keras.Model(inputs=model.inputs, outputs=model.get_layer(final_layer).output)(sample)\n",
    "    )\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f890626c",
   "metadata": {},
   "source": [
    "## Feature Extraction Pipeline\n",
    "Building the feature extraction pipeline using an Inception Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de6af1d",
   "metadata": {},
   "source": [
    "Loading and preparing the DCE-based dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07063346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (3240000, 20)\n",
      "Reshaped data shape: (10800, 1, 300, 20)\n",
      "Original targets shape: (10800,)\n"
     ]
    }
   ],
   "source": [
    "# loading data and targets\n",
    "data = np.loadtxt(os.path.join(\"..\",\"..\", \"data\", \"processed\", \"EEG_filt_20_electrodes.csv\"), delimiter=',')\n",
    "targets = np.loadtxt(os.path.join(\"..\",\"..\", \"data\", \"processed\", \"EEG_filt_first_8_electrodes_targets.csv\"), delimiter=',')\n",
    "\n",
    "# encoding targets (from string to int)\n",
    "targets[targets == 0] = 0\n",
    "targets[targets == 1] = 1 # 19494 subjects of this class\n",
    "targets[targets == 2] = 2\n",
    "targets[targets == 3] = 3 # 11286 subjects of this class\n",
    "targets = targets.astype(int)\n",
    "\n",
    "print(f\"Original data shape: {data.shape}\")\n",
    "data_reshape = data.reshape(10800, 1,300, 20) \n",
    "\n",
    "print(f\"Reshaped data shape: {data_reshape.shape}\")\n",
    "print(f\"Original targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02a58a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 65.4093722285802, data_reshape: 65.4093722285802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10800, 1, 300, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"data: {data[3,1]}, data_reshape: {data_reshape[0,0,3,1]}\")\n",
    "data_reshape.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2552d6",
   "metadata": {},
   "source": [
    "### Train-Test-Split\n",
    "Splitting DCE-based dataset into train/holdout sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c0a3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data train set: (9720, 1, 300, 20)\n",
      "Holdout data test set: (1080, 1, 300, 20)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_holdout, y_train, y_holdout = train_test_split(\n",
    "    data_reshape,\n",
    "    targets,\n",
    "    test_size=0.1,\n",
    "    shuffle=True,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "print(f\"Original data train set: {x_train.shape}\")\n",
    "print(f\"Holdout data test set: {x_holdout.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df08685d",
   "metadata": {},
   "source": [
    "### Architecture Optimization\n",
    "Building the optimizable iCNN skeleton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a537d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the Inception skeleton\n",
    "inception_hyper_model = InceptionHyperModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b0de67",
   "metadata": {},
   "source": [
    "Setting up the architecture tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ccd29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ../../models/updatedInception/20_electrodes_4_classes_10_test_90_train_feature_extractor/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ../../models/updatedInception/20_electrodes_4_classes_10_test_90_train_feature_extractor/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 16:11:04.183330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-23 16:11:04.183425: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-23 16:11:04.183475: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-23 16:11:04.183508: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-23 16:11:04.183541: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-01-23 16:11:04.183573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-01-23 16:11:04.183604: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-23 16:11:04.183635: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-23 16:11:04.183666: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-23 16:11:04.183671: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-23 16:11:04.184158: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# setting up the optimization process\n",
    "tuner = BayesianOptimization(\n",
    "    hypermodel=inception_hyper_model,\n",
    "    objective=\"val_loss\",\n",
    "    num_initial_points=25,\n",
    "    max_trials=15,\n",
    "    directory=os.path.join(\"..\",\"..\", \"models\",\"updatedInception\"),\n",
    "    project_name=\"20_electrodes_4_classes_10_test_90_train_feature_extractor\",\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed4c6ec",
   "metadata": {},
   "source": [
    "Defining callback functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6f1955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=20\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", \n",
    "        factor=0.1, \n",
    "        patience=10, \n",
    "        mode=\"auto\", \n",
    "        min_delta=0.0001, \n",
    "        cooldown=0, \n",
    "        min_lr=1.0e-6\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809b0c02",
   "metadata": {},
   "source": [
    "Running the tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc0f8bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# running the search\n",
    "tuner.search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=250,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d21f28",
   "metadata": {},
   "source": [
    "### Building The Model\n",
    "Getting the best feature extraction model from the tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96bdd925",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_extractor = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7afe788",
   "metadata": {},
   "source": [
    "### Feature Extraction Process\n",
    "Using the model to extract predictive patterns from the DCE-based dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c302ae4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (9720, 33)\n",
      "Holdout dataset shape: (1080, 33)\n"
     ]
    }
   ],
   "source": [
    "train_features = []\n",
    "holdout_features = []\n",
    "\n",
    "# extracting trian features\n",
    "for sample in x_train:\n",
    "    sample_features = get_features_extracted(best_feature_extractor, \"global_average_pooling2d\", sample)\n",
    "    train_features.append(sample_features)\n",
    "    \n",
    "# extracting holdout features\n",
    "for sample in x_holdout:\n",
    "    sample_features = get_features_extracted(best_feature_extractor, \"global_average_pooling2d\", sample)\n",
    "    holdout_features.append(sample_features)\n",
    "\n",
    "# assembling feature dataframes\n",
    "train_features_df = pd.DataFrame(np.array(train_features).reshape((len(train_features),len(train_features[0][0])))) \n",
    "train_features_df[\"CLASS\"] = y_train\n",
    "\n",
    "holdout_features_df = pd.DataFrame(np.array(holdout_features).reshape((len(holdout_features),len(holdout_features[0][0]))))\n",
    "holdout_features_df[\"CLASS\"] = y_holdout\n",
    "\n",
    "print(f\"Train dataset shape: {train_features_df.shape}\")\n",
    "print(f\"Holdout dataset shape: {holdout_features_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c2a562",
   "metadata": {},
   "source": [
    "## Machine Learning Classification Experiment\n",
    "Renaming the columns to avoid errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dbaf926",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_df.columns = train_features_df.columns.astype(str)\n",
    "holdout_features_df.columns = holdout_features_df.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6f984ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 7ms/step - loss: 0.2822 - accuracy: 0.9009\n",
      "[test loss, test accuracy]: [0.28218817710876465, 0.9009259343147278]\n"
     ]
    }
   ],
   "source": [
    "eval_result = best_feature_extractor.evaluate(x_holdout, y_holdout)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe11e568",
   "metadata": {},
   "source": [
    "Setting up the ML classification pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "774fc97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0522d_row15_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0522d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0522d_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_0522d_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0522d_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_0522d_row0_col1\" class=\"data row0 col1\" >8444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0522d_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_0522d_row1_col1\" class=\"data row1 col1\" >CLASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0522d_row2_col0\" class=\"data row2 col0\" >Target Type</td>\n",
       "      <td id=\"T_0522d_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0522d_row3_col0\" class=\"data row3 col0\" >Label Encoded</td>\n",
       "      <td id=\"T_0522d_row3_col1\" class=\"data row3 col1\" >0: 0, 1: 1, 2: 2, 3: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0522d_row4_col0\" class=\"data row4 col0\" >Original Data</td>\n",
       "      <td id=\"T_0522d_row4_col1\" class=\"data row4 col1\" >(9720, 33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_0522d_row5_col0\" class=\"data row5 col0\" >Missing Values</td>\n",
       "      <td id=\"T_0522d_row5_col1\" class=\"data row5 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_0522d_row6_col0\" class=\"data row6 col0\" >Numeric Features</td>\n",
       "      <td id=\"T_0522d_row6_col1\" class=\"data row6 col1\" >30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_0522d_row7_col0\" class=\"data row7 col0\" >Categorical Features</td>\n",
       "      <td id=\"T_0522d_row7_col1\" class=\"data row7 col1\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_0522d_row8_col0\" class=\"data row8 col0\" >Transformed Train Set</td>\n",
       "      <td id=\"T_0522d_row8_col1\" class=\"data row8 col1\" >(9720, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_0522d_row9_col0\" class=\"data row9 col0\" >Transformed Test Set</td>\n",
       "      <td id=\"T_0522d_row9_col1\" class=\"data row9 col1\" >(1080, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_0522d_row10_col0\" class=\"data row10 col0\" >Shuffle Train-Test</td>\n",
       "      <td id=\"T_0522d_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_0522d_row11_col0\" class=\"data row11 col0\" >Stratify Train-Test</td>\n",
       "      <td id=\"T_0522d_row11_col1\" class=\"data row11 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_0522d_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_0522d_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_0522d_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_0522d_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_0522d_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_0522d_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_0522d_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_0522d_row15_col1\" class=\"data row15 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_0522d_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_0522d_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_0522d_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_0522d_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_0522d_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_0522d_row18_col1\" class=\"data row18 col1\" >0542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_0522d_row19_col0\" class=\"data row19 col0\" >Fix Imbalance</td>\n",
       "      <td id=\"T_0522d_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0522d_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_0522d_row20_col0\" class=\"data row20 col0\" >Fix Imbalance Method</td>\n",
       "      <td id=\"T_0522d_row20_col1\" class=\"data row20 col1\" >SMOTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f873a99be50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classif_exp = setup(\n",
    "    data=train_features_df,\n",
    "    test_data=holdout_features_df,\n",
    "    target=\"CLASS\",\n",
    "    fold_shuffle=True,\n",
    "    preprocess = False,\n",
    "    use_gpu=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab1fe9b",
   "metadata": {},
   "source": [
    "#### Models Comparison\n",
    "Comparing different machine learning model performances for the task of classifying DCE-base features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bdd20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d806d8382b3b43a69660d0ae6c5bbe48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Processing: ', max=79)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>16:13:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Fitting 10 Folds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            \n",
       "                                                                            \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                      16:13:54\n",
       "Status     . . . . . . . . . . . . . . . . . .              Fitting 10 Folds\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  Gradient Boosting Classifier"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4016a th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4016a_row0_col0, #T_4016a_row0_col1, #T_4016a_row0_col2, #T_4016a_row0_col3, #T_4016a_row0_col4, #T_4016a_row0_col5, #T_4016a_row0_col6, #T_4016a_row0_col7, #T_4016a_row0_col8, #T_4016a_row1_col0, #T_4016a_row1_col1, #T_4016a_row1_col2, #T_4016a_row1_col3, #T_4016a_row1_col4, #T_4016a_row1_col5, #T_4016a_row1_col6, #T_4016a_row1_col7, #T_4016a_row1_col8, #T_4016a_row2_col0, #T_4016a_row2_col1, #T_4016a_row2_col2, #T_4016a_row2_col3, #T_4016a_row2_col4, #T_4016a_row2_col5, #T_4016a_row2_col6, #T_4016a_row2_col7, #T_4016a_row2_col8, #T_4016a_row3_col0, #T_4016a_row3_col1, #T_4016a_row3_col2, #T_4016a_row3_col3, #T_4016a_row3_col4, #T_4016a_row3_col5, #T_4016a_row3_col6, #T_4016a_row3_col7, #T_4016a_row3_col8, #T_4016a_row4_col0, #T_4016a_row4_col1, #T_4016a_row4_col2, #T_4016a_row4_col3, #T_4016a_row4_col4, #T_4016a_row4_col5, #T_4016a_row4_col6, #T_4016a_row4_col7, #T_4016a_row4_col8, #T_4016a_row5_col0, #T_4016a_row5_col1, #T_4016a_row5_col2, #T_4016a_row5_col3, #T_4016a_row5_col4, #T_4016a_row5_col5, #T_4016a_row5_col6, #T_4016a_row5_col7, #T_4016a_row5_col8, #T_4016a_row6_col0, #T_4016a_row6_col1, #T_4016a_row6_col2, #T_4016a_row6_col3, #T_4016a_row6_col4, #T_4016a_row6_col5, #T_4016a_row6_col6, #T_4016a_row6_col7, #T_4016a_row6_col8, #T_4016a_row7_col0, #T_4016a_row7_col1, #T_4016a_row7_col2, #T_4016a_row7_col3, #T_4016a_row7_col4, #T_4016a_row7_col5, #T_4016a_row7_col6, #T_4016a_row7_col7, #T_4016a_row7_col8, #T_4016a_row8_col0, #T_4016a_row8_col1, #T_4016a_row8_col2, #T_4016a_row8_col3, #T_4016a_row8_col4, #T_4016a_row8_col5, #T_4016a_row8_col6, #T_4016a_row8_col7, #T_4016a_row8_col8 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4016a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4016a_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_4016a_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_4016a_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_4016a_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_4016a_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_4016a_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_4016a_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_4016a_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_4016a_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4016a_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
       "      <td id=\"T_4016a_row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_4016a_row0_col1\" class=\"data row0 col1\" >0.9447</td>\n",
       "      <td id=\"T_4016a_row0_col2\" class=\"data row0 col2\" >0.9911</td>\n",
       "      <td id=\"T_4016a_row0_col3\" class=\"data row0 col3\" >0.9381</td>\n",
       "      <td id=\"T_4016a_row0_col4\" class=\"data row0 col4\" >0.9448</td>\n",
       "      <td id=\"T_4016a_row0_col5\" class=\"data row0 col5\" >0.9446</td>\n",
       "      <td id=\"T_4016a_row0_col6\" class=\"data row0 col6\" >0.9127</td>\n",
       "      <td id=\"T_4016a_row0_col7\" class=\"data row0 col7\" >0.9127</td>\n",
       "      <td id=\"T_4016a_row0_col8\" class=\"data row0 col8\" >0.7870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4016a_level0_row1\" class=\"row_heading level0 row1\" >knn</th>\n",
       "      <td id=\"T_4016a_row1_col0\" class=\"data row1 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_4016a_row1_col1\" class=\"data row1 col1\" >0.9431</td>\n",
       "      <td id=\"T_4016a_row1_col2\" class=\"data row1 col2\" >0.9813</td>\n",
       "      <td id=\"T_4016a_row1_col3\" class=\"data row1 col3\" >0.9363</td>\n",
       "      <td id=\"T_4016a_row1_col4\" class=\"data row1 col4\" >0.9433</td>\n",
       "      <td id=\"T_4016a_row1_col5\" class=\"data row1 col5\" >0.9431</td>\n",
       "      <td id=\"T_4016a_row1_col6\" class=\"data row1 col6\" >0.9103</td>\n",
       "      <td id=\"T_4016a_row1_col7\" class=\"data row1 col7\" >0.9104</td>\n",
       "      <td id=\"T_4016a_row1_col8\" class=\"data row1 col8\" >0.0480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4016a_level0_row2\" class=\"row_heading level0 row2\" >lr</th>\n",
       "      <td id=\"T_4016a_row2_col0\" class=\"data row2 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_4016a_row2_col1\" class=\"data row2 col1\" >0.9247</td>\n",
       "      <td id=\"T_4016a_row2_col2\" class=\"data row2 col2\" >0.9845</td>\n",
       "      <td id=\"T_4016a_row2_col3\" class=\"data row2 col3\" >0.9121</td>\n",
       "      <td id=\"T_4016a_row2_col4\" class=\"data row2 col4\" >0.9249</td>\n",
       "      <td id=\"T_4016a_row2_col5\" class=\"data row2 col5\" >0.9245</td>\n",
       "      <td id=\"T_4016a_row2_col6\" class=\"data row2 col6\" >0.8804</td>\n",
       "      <td id=\"T_4016a_row2_col7\" class=\"data row2 col7\" >0.8807</td>\n",
       "      <td id=\"T_4016a_row2_col8\" class=\"data row2 col8\" >0.2130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4016a_level0_row3\" class=\"row_heading level0 row3\" >dt</th>\n",
       "      <td id=\"T_4016a_row3_col0\" class=\"data row3 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_4016a_row3_col1\" class=\"data row3 col1\" >0.9153</td>\n",
       "      <td id=\"T_4016a_row3_col2\" class=\"data row3 col2\" >0.9353</td>\n",
       "      <td id=\"T_4016a_row3_col3\" class=\"data row3 col3\" >0.9069</td>\n",
       "      <td id=\"T_4016a_row3_col4\" class=\"data row3 col4\" >0.9155</td>\n",
       "      <td id=\"T_4016a_row3_col5\" class=\"data row3 col5\" >0.9153</td>\n",
       "      <td id=\"T_4016a_row3_col6\" class=\"data row3 col6\" >0.8666</td>\n",
       "      <td id=\"T_4016a_row3_col7\" class=\"data row3 col7\" >0.8667</td>\n",
       "      <td id=\"T_4016a_row3_col8\" class=\"data row3 col8\" >0.1780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4016a_level0_row4\" class=\"row_heading level0 row4\" >svm</th>\n",
       "      <td id=\"T_4016a_row4_col0\" class=\"data row4 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_4016a_row4_col1\" class=\"data row4 col1\" >0.9032</td>\n",
       "      <td id=\"T_4016a_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n",
       "      <td id=\"T_4016a_row4_col3\" class=\"data row4 col3\" >0.8873</td>\n",
       "      <td id=\"T_4016a_row4_col4\" class=\"data row4 col4\" >0.9042</td>\n",
       "      <td id=\"T_4016a_row4_col5\" class=\"data row4 col5\" >0.8991</td>\n",
       "      <td id=\"T_4016a_row4_col6\" class=\"data row4 col6\" >0.8441</td>\n",
       "      <td id=\"T_4016a_row4_col7\" class=\"data row4 col7\" >0.8482</td>\n",
       "      <td id=\"T_4016a_row4_col8\" class=\"data row4 col8\" >0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4016a_level0_row5\" class=\"row_heading level0 row5\" >ridge</th>\n",
       "      <td id=\"T_4016a_row5_col0\" class=\"data row5 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_4016a_row5_col1\" class=\"data row5 col1\" >0.8564</td>\n",
       "      <td id=\"T_4016a_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n",
       "      <td id=\"T_4016a_row5_col3\" class=\"data row5 col3\" >0.8177</td>\n",
       "      <td id=\"T_4016a_row5_col4\" class=\"data row5 col4\" >0.8591</td>\n",
       "      <td id=\"T_4016a_row5_col5\" class=\"data row5 col5\" >0.8471</td>\n",
       "      <td id=\"T_4016a_row5_col6\" class=\"data row5 col6\" >0.7654</td>\n",
       "      <td id=\"T_4016a_row5_col7\" class=\"data row5 col7\" >0.7744</td>\n",
       "      <td id=\"T_4016a_row5_col8\" class=\"data row5 col8\" >0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4016a_level0_row6\" class=\"row_heading level0 row6\" >nb</th>\n",
       "      <td id=\"T_4016a_row6_col0\" class=\"data row6 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_4016a_row6_col1\" class=\"data row6 col1\" >0.8427</td>\n",
       "      <td id=\"T_4016a_row6_col2\" class=\"data row6 col2\" >0.9595</td>\n",
       "      <td id=\"T_4016a_row6_col3\" class=\"data row6 col3\" >0.8448</td>\n",
       "      <td id=\"T_4016a_row6_col4\" class=\"data row6 col4\" >0.8528</td>\n",
       "      <td id=\"T_4016a_row6_col5\" class=\"data row6 col5\" >0.8379</td>\n",
       "      <td id=\"T_4016a_row6_col6\" class=\"data row6 col6\" >0.7554</td>\n",
       "      <td id=\"T_4016a_row6_col7\" class=\"data row6 col7\" >0.7616</td>\n",
       "      <td id=\"T_4016a_row6_col8\" class=\"data row6 col8\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4016a_level0_row7\" class=\"row_heading level0 row7\" >ada</th>\n",
       "      <td id=\"T_4016a_row7_col0\" class=\"data row7 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_4016a_row7_col1\" class=\"data row7 col1\" >0.8378</td>\n",
       "      <td id=\"T_4016a_row7_col2\" class=\"data row7 col2\" >0.9100</td>\n",
       "      <td id=\"T_4016a_row7_col3\" class=\"data row7 col3\" >0.8304</td>\n",
       "      <td id=\"T_4016a_row7_col4\" class=\"data row7 col4\" >0.8446</td>\n",
       "      <td id=\"T_4016a_row7_col5\" class=\"data row7 col5\" >0.8248</td>\n",
       "      <td id=\"T_4016a_row7_col6\" class=\"data row7 col6\" >0.7412</td>\n",
       "      <td id=\"T_4016a_row7_col7\" class=\"data row7 col7\" >0.7506</td>\n",
       "      <td id=\"T_4016a_row7_col8\" class=\"data row7 col8\" >1.2330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4016a_level0_row8\" class=\"row_heading level0 row8\" >qda</th>\n",
       "      <td id=\"T_4016a_row8_col0\" class=\"data row8 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_4016a_row8_col1\" class=\"data row8 col1\" >0.5441</td>\n",
       "      <td id=\"T_4016a_row8_col2\" class=\"data row8 col2\" >0.8961</td>\n",
       "      <td id=\"T_4016a_row8_col3\" class=\"data row8 col3\" >0.6858</td>\n",
       "      <td id=\"T_4016a_row8_col4\" class=\"data row8 col4\" >0.7532</td>\n",
       "      <td id=\"T_4016a_row8_col5\" class=\"data row8 col5\" >0.5210</td>\n",
       "      <td id=\"T_4016a_row8_col6\" class=\"data row8 col6\" >0.3998</td>\n",
       "      <td id=\"T_4016a_row8_col7\" class=\"data row8 col7\" >0.4517</td>\n",
       "      <td id=\"T_4016a_row8_col8\" class=\"data row8 col8\" >0.0340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8830852e60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = compare_models(sort=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c42ddd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "holdout_preds = predict_model(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5380325",
   "metadata": {},
   "source": [
    "## Models Serialization\n",
    "Serializing feature extraction as well as ml classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bacd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best feature extraction icnn model\n",
    "best_feature_extractor.save(\n",
    "    os.path.join(\"..\",\"..\", \"models\", \"updatedInception\", \"20_electrodes_4_classes_10_test_90_train_best_feature_extractor\"),\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=\"h5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b8451f",
   "metadata": {},
   "source": [
    "## Data Serialization\n",
    "Serializing the processed train and holdout validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ea49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_df.to_csv(os.path.join(\"..\",\"..\", \"data\", \"finalized\",\"updatedInception\", \"20_electrodes_4_classes_10_test_90_train_train_df.csv\"), index=False)\n",
    "holdout_features_df.to_csv(os.path.join(\"..\",\"..\", \"data\", \"finalized\",\"updatedInception\", \"20_electrodes_4_classes_10_test_90_train_holdout_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db9c28",
   "metadata": {},
   "source": [
    "## Ploting model\n",
    "\n",
    "ploting the confusion_matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4da2b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(\n",
    "    best_model, \n",
    "    plot = 'confusion_matrix'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f24f1",
   "metadata": {},
   "source": [
    "ploting the learning curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c8ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(\n",
    "    best_model, \n",
    "    plot = 'auc', \n",
    "    use_train_data = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba53bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
